\documentclass[a4paper,12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{subfig}
\usepackage[countmax]{subfloat}
\newcommand{\tab}{\hspace*{2em}}
%opening

\begin{document}


\begin{center}
{\Large Previous Research}

\emph{Matthew Le}
\end{center}
\vspace{-2ex}

I am currently working on two research projects, both of which are funded by the NSF Research Experience for Undergraduates (REU) program. The first project is under the guidance of Professor Eric Van Wyk, dealing with finding ways to design programming languages, such that they can easily be extended, to support additional constructs. The second project that I have been working on deals with investigating the effects of Pacific Ocean warming on Atlantic hurricane activity. For this project, I have been working under the mentorship of Professor Vipin Kumar while working closely with one of his graduate students and a senior research scientist in Professor Kumar's laboratory.

Domain specific languages (e.g. R, MATLAB, SQL, \textit{etc.}) have become popular because they allow the programmer to code at a high level of abstraction using constructs relevant to their discipline while enjoying the benefits of domain specific optimizations. Our research aims to implement domain specific constructs to existing general purpose programming languages, via language extensions.  These extensions then get reduced to constructs that already exist in the host language, using a technique known as ``forwarding,'' which allows for extensions to be independently and simultaneously developed. 

The extension that I have been working on provides support for matrices and the operations that accompany them.  One of the main goals of this extension is to make matrices appear to the programmer as if they are first-class, built-in data types.  To do this, we first added a new type to the language's type system, which then gets reduced, or forwards to a type that already exists in the host language, in this case structs (the underlying representation we have chosen for matrices).  This allows the programmer to declare a matrix variable in the same manner they would create any other type of variable.  The next big task necessary to incorporate matrices into the language was to overload many of the operators in the host language, which can be used for the host primitive types.  First, we overloaded the arithmetic operators, so that matrix arithmetic can be done by using the basic operators such as +, -, *, and /.  This allows us to abstract away the details of complicated matrix arithmetic algorithms.  Matrix multiplication is a perfect example of this.  To multiply two matrices together, is a fairly complex task, but we are able to generate the code to do this for the programmer, as well as perform optimizations such as parallelizing the loops used to compute the result.  In addition to this, we have also overloaded the array reference and assignment operators, so that the programmer can also reference multiple elements, as well as assign to multiple elements of a matrix in one line of code. 

Since we are using forwarding to implement these language extensions, the host language remains unchanged by these extensions.  The benefit to this is that if someone else wanted to design a different extension for this same host language, their work wouldn't be affected by the extension that I have created, and vise versa.  Another benefit to this is that if the host language is modified in some way, then the changes do not need to be done to the extensions, since they all reduce to constructs in the host language.  For example, if the representation of the symbol table changed, you would only need to modify the host language to accommodate this modification.  

%The project that I am working on implements this idea by first creating a host language. For this, we have chosen a prototype language, which is a subset of C. The role of the host language is to show the state of a general purpose programming language in its initial state without any extensions.  We chose to use a subset of C because its low level of abstraction gives rise to programming complexity, but when used correctly it can yield code that runs very efficiently. After the host language was implemented, we began working on extensions. The extension that I have been working on adds support for matrices, and the operations that accompany them. We create these extensions using a technique known as ``forwarding'', which works by reducing extensions to constructs that already exist in the host language.  The extension that I am working on makes heavy use of forwarding, such that this extensions is ``pure'', meaning it is completely reducible to constructs existing in the host language.  The benefit to this is that if the host language gets updated, then the extension does not need to be modified.  Also, this allows for other language extensions to be simultaneously and independently implemented.

%I began implementing the extension by first designing the underlying representation of matrices. Since we want this matrix extension to generalize to any number of dimensions, we chose to represent matrices as a structure containing the size of each dimension, and the data the matrix contains. We then index matrices using row-major indexing. After designing the underlying representation, we created an additional type for matrices, which then forwards to a host type, in this case we forward to the host struct type. We then created syntax and abstract productions for declaring matrices.  Matrix declarations are really no different than declaring any other variable, we simply need to add the name of the matrix being declared to the symbol table. Another necessity that we implemented was matrix initialization. This production forwards to a sequence of assignment statements, where we allocate space for the structure, the dimension sizes array, and the data array. A few other productions that we added to the core matrix extension include matrix references, matrix arithmetic, and printing of matrices.  

%After creating an extension that simply introduces this new data structure and some very basic operations, we started adding some of the domain specific features that are found in MATLAB.  Such additional functions include logical indexing, referencing multiple elements of a matrix at a time, assigning to multiple elements of a matrix, and matrix permutations.  We ended up putting this functionality into an extension of its own, showing that not only host languages can be extended in a modular way, but extensions can also be further extended in a modular way.  These additional features have presented many opportunities for generating parallel C code, which is something that we are currently exploring now.

As of now, we currently have a functioning language extensions that supports just about everything that one would be able to do in MATLAB. We are able to generate C code from this extension, and are currently working on the optimization phase of the project. I have implemented many of the algorithms that we use in the data mining research lab that I am also apart of, using the language extension that I have created. The two versions of most algorithms run in about the same amount of time, and produce the same results. This leads me to believe that once we are able to generate parallel code, we will have a large runtime advantage on top of the fact that we have successfully integrated this extension into a general purpose language 

A second research opportunity that I am currently working on is another NSF REU funded project in the field of climate data mining, under the guidance of graduate student James Faghmous and his advisor Professor Vipin Kumar.  The El-Ni\~{n}o Southern Oscillation (ENSO) is a phenomenon where Pacific Ocean warming has been linked to Atlantic hurricane activity\cite{enso}.  The problem is that the correlation between the two is quite poor.  This research effort aims to further investigate this relationship. 

When I began working on this project, James had already developed a method that explained the Pacific-Atlantic relationship more accurately than ENSO. Traditionally, climate scientists have expressed the impact of the Pacific Ocean on Atlantic hurricanes by monitoring fixed regions in the ocean and recording their sea surface temperature. James proposed that instead of monitoring the temperature of the Pacific Ocean, one can monitor the location of the warming, i.e. what subset of the Pacific is the warmest. This index correlated with Atlantic hurricanes much more than traditional ENSO indices.. After finalizing the original index, I went on to experiment with variations of the index to increase its accuracy. Many of these variations involved incorporating additional variables in addition to sea surface temperature.  After a few months, I had come up with an index of my own that performed better than the previous one with an increase from 0.6 to 0.8 correlation between the index and Atlantic hurricane counts. This index has remained our top performing predictor of Atlantic hurricane activity when we restrict ourselves to the Pacific Ocean. Over the past few months we have been compiling our results and testing the validity and significance of the index.  Since we have a relatively limited amount of data (about 30 years worth) and the auto-correlated nature of climate data (data that are close in space and time tend to be related), we could not use traditional significant tests (e.g. t-test) to ensure that the high correlation between our index and the Atlantic hurricane activity is not due to random chance.  Instead, I helped implement a variety of experiments that use randomization and cross validation (regression analysis where portions of data are excluded from training) to verify the significance of our results

In addition to conducting research, I have also had a few gratifying experiences presenting my results. About four months into working on my programming languages research project, we presented at the University of Minnesota Undergraduate Research Symposium. This was an interesting experience because we were not just presenting to computer scientists. It proved to be a rather difficult task to explain what we were working on to the general public who had never been exposed to computer science. I am now more thoughtful about my communication as I value the importance of communicating my results to the broader community. I also had the opportunity to present a poster on my work at the annual NSF Expeditions Grant Workshop, where I interacted with a broad range of scientists, faculty, and students from over 10 universities.

I have had a great time working on these two projects, and feel that they have stimulated my interest in conducting research in the future.  I certainly have a different perspective on conducting research now that I have had some exposure to it, and feel that I am much more prepared than previously in carrying out research at the graduate level.  
\vspace{-2ex}

\begin{thebibliography}{9} \vspace{-1ex}
\footnotesize
\bibitem{enso}M.C. Bove, J.J. O'Brien, J.B. Elsner, C.W. Landsea, X. Niu.  Effect of El Nino on U.S. Landfalling Hurricanes, Revisted.  \textit{Bulletin of the American Meteorological Society}, Volume 79, Number 11
\end{thebibliography}

\end{document}










